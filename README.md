# Whisper Fine-Tuning FD

Ce projet permet de prÃ©parer un dataset audio/texte, dâ€™entraÃ®ner un modÃ¨le Whisper sur vos propres donnÃ©es, et dâ€™Ã©valuer ses performances.

## ğŸ§° PrÃ©requis

- Python 3.8+
- CrÃ©ez un environnement virtuel (optionnel mais recommandÃ©) :

```bash
python -m venv whisper_env
# Puis activez-le
whisper_env\Scripts\activate  # Sous Windows
source whisper_env/bin/activate  # Sous Linux/macOS
```

- Installez les dÃ©pendances nÃ©cessaires :

```bash
pip install torch pandas numpy librosa tqdm scikit-learn jiwer openai-whisper
```

## ğŸ§ PrÃ©paration des donnÃ©es

1. TÃ©lÃ©chargez les donnÃ©es depuis Google Drive :
   ğŸ‘‰ https://drive.google.com/file/d/1PtJS3BI5wW0N8z7lu7s_B5ZtsL5X9ZDS/view?usp=drive_link

2. Placez les dossiers `all_audio/` et `all_text/` Ã  la **racine du projet** (mÃªme niveau que `appmodel.py`).

## ğŸš€ Split & entraÃ®nement

Lancez `appmodel.py` pour effectuer :

- Le **split du dataset** en `train.csv` / `test.csv`
- Lâ€™entraÃ®nement du modÃ¨le sur vos donnÃ©es personnalisÃ©es :

```python
from appmodel import WhisperFineTunerRobust, WhisperDataset
import torch

train_dataset = WhisperDataset("train.csv")
tuner = WhisperFineTunerRobust("tiny", language="EN")
tuner.train(train_dataset, epochs=2, batch_size=6, lr=1e-5)
tuner.save_model("whisper_finetuned_local.pth")
```

- Pour **rÃ©entraÃ®ner** un modÃ¨le dÃ©jÃ  sauvegardÃ© :

```python
tuner.model.load_state_dict(torch.load("whisper_finetuned_local.pth", map_location=tuner.device))
tuner.train(train_dataset, epochs=2, batch_size=6, lr=1e-5)
```

## âœ… Conseils

- Pour accÃ©lÃ©rer l'entraÃ®nement, commencez avec un sous-ensemble du dataset (e.g., 100 premiers exemples).
- Les tailles de modÃ¨les disponibles : `tiny`, `base`, `small`, `medium`, `large`.

---

